#  Mamba 

看上去 `SSM` 就挺好了, 为啥还不行呢, 因为SSM 有两个强假设: `线性` 和 `时不变`, `mamba` 就是对这两个进行改进, 放开了这俩约束

所以 SSM 的问题：
> 矩阵不随输入不同而变化，无法针对输入做针对性推理, Linear Time Invariance(LTI)规定 SSM中的A、B、C不随输入不同而不同
> 使得SSM无法针对输入做针对性的推理
> ![](https://image.chiullian.cn/img/202411251546615.png)

- 即这里的不变性特指：推理时不随输入变化而变化，但在训练过程中，矩阵是可以根据需要去做梯度下降而变化的

Mamba 的模型：
* 顺带提前说一嘴，SSM之外，对于mamba，训练时其参数也必然会变
* 但推理时，ssm 不会随着输入的不同 做针对性的推理，即任何输入都是一视同仁，至于参数也不会变
* 但mamba会对输入做选择性推理，虽然推理时本身的参数也不会变，但会对不同的输入给予不同的有区别的对待，比如有的重点关注，有的选择性忽略


> 总之，虽然Mamba模型在推理时参数本身也不变，但由于其设计中引入的选择性机制，使得模型能够根据不同输入token的特点
> 进行有区别的对待，这与SSM模型相比是一个显著的进步。且Mamba这种选择性是通过训练阶段的参数学习来实现的(根据训练阶段学习到的参数对不同的输入给予不同的处理)，而不是在推理阶段动态调整参数

#### S4 模型对信息的重要性聚焦不予处理

没有选择性，S4会花费相同的“精力”来处理每个单词：
![](https://image.chiullian.cn/img/202411251557457.png)

但如果是一个试图对这句话的意图进行分类的模型，它可能会想更多地“关注”order、hamburger，而不是want、to
如下图所示，而通过使模型参数成为输入的函数，模型就可以做到“专注于”输入中对于当前任务更重要的部分，而这正是mamba的创新点之一

![](https://image.chiullian.cn/img/202411251556416.png)

### Mamba 模型的三大创新
> Mamba = 有选择处理信息 + 硬件感知算法 + 更简单的SSM架构

`Transformer` 就像人类每写一个字之前，都把前面的所有字+输入都复习一遍，所以写的慢
`RNN` 每次只参考前面固定的字数,写的快是快，但容易忘掉更前面的内容
`SSM` 的问题在于其中的矩阵A B C不随输入不同而不同，即无法针对不同的输入针对性的推理

> Mamba的解决办法是，相比SSM压缩所有历史记录，mamba设计了一个简单的选择机制，通过“参数化SSM的输入”，让模型对信息有选择性处理，以便关注或忽略特定的输入